{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73deb080",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a576f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81163d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for default/terminating cases\n",
    "\n",
    "MAX_ERROR = 10**(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec40b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text files\n",
    "\n",
    "mdp1 = open(\"mdp-10-5.txt\", 'rt')\n",
    "mdp2 = open(\"mdp-2-2.txt\", 'rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78545448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each line from the text files\n",
    "\n",
    "def extract_info(mdp):\n",
    "    # To store each line of the file\n",
    "    lines = []\n",
    "    \n",
    "    # To store each line of the file\n",
    "    for line in mdp: \n",
    "        lines.append(line)\n",
    "    \n",
    "    # To store number of states and actions of the mdp\n",
    "    n_states = int(lines[0].split()[1])\n",
    "    n_actions = int(lines[1].split()[1])\n",
    "    \n",
    "    # To define values of states and actions\n",
    "    state = [i for i in range(n_states)]\n",
    "    action = [i for i in range(n_actions)]\n",
    "    \n",
    "    # To store the reward and transition probability for a particular set of initial state, action and final state \n",
    "    trans_model = [[[(0,0) for i in range(n_states)] for j in range(n_actions)] for k in range(n_states)]\n",
    "    \n",
    "    for line in lines[2:len(lines)-1]:\n",
    "        splitline = line.split()\n",
    "        \n",
    "        # Accessing each 'token' of the line to store the information in the right place\n",
    "        trans_model[eval(splitline[1])][eval(splitline[2])][eval(splitline[3])] = (eval(splitline[4]),eval(splitline[5]))\n",
    "    \n",
    "    gamma = float(lines[len(lines)-1].split()[1])\n",
    "    \n",
    "    return n_states, n_actions, state, action, trans_model, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c33734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iter(num_s, num_a, state, action, trans_model, gamma):\n",
    "    \n",
    "    # Initialise State Values and policies\n",
    "\n",
    "    values = np.zeros(num_s)\n",
    "    policy = np.random.randint(0, num_a, num_s)\n",
    "\n",
    "    while True:\n",
    "        while True:\n",
    "            # Policy Evaluation\n",
    "            delta = 0\n",
    "            \n",
    "            for s in state:\n",
    "                V0 = values[s]\n",
    "                for a in action:\n",
    "                    v = 0\n",
    "                    \n",
    "                    for s_next in state:\n",
    "                        # Update the state value \n",
    "                        v += trans_model[s][a][s_next][1]*(trans_model[s][a][s_next][0] + gamma * values[s_next])\n",
    "                    \n",
    "                    values[s] = max(values[s],v)\n",
    "                    \n",
    "                delta = max(delta, abs(V0 - values[s]))\n",
    "            if delta < MAX_ERROR: \n",
    "                break\n",
    "\n",
    "        # 3. Policy Improvement\n",
    "        policy_stable = True\n",
    "        \n",
    "        for s in state:\n",
    "            old_action = policy[s]\n",
    "            \n",
    "            # To determine the optimal policy\n",
    "            action_max = 0\n",
    "            v_list = []\n",
    "            \n",
    "            for a in action:\n",
    "                v = 0\n",
    "                \n",
    "                for s_next in state:\n",
    "                    # To determine the state value\n",
    "                    v += trans_model[s][a][s_next][1] * (trans_model[s][a][s_next][0] + gamma * values[s_next])\n",
    "                v_list.append(v)\n",
    "                \n",
    "            # To determine the optimal policy based on the maximum state-value obtained    \n",
    "            policy[s] = np.argmax(v_list)\n",
    "            if old_action != policy[s]: \n",
    "                policy_stable = False\n",
    "        if policy_stable: \n",
    "            break        \n",
    "    \n",
    "    return values, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3803423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mdp1\n",
    "\n",
    "num_s, num_a, state, action, trans_model, gamma = extract_info(mdp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b7260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f5bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1, pol1 = policy_iter(num_s, num_a, state, action, trans_model, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880a3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results into a text file\n",
    "\n",
    "file = open('sol-PI-mdp-10-5.txt','w')\n",
    "lines = []\n",
    "for s in state:\n",
    "    lines.append(f\"{'{:.6f}'.format(round(val1[s],6))} {pol1[s]}\\n\")\n",
    "file.writelines(lines)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mdp2\n",
    "\n",
    "num_s, num_a, state, action, trans_model, gamma = extract_info(mdp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4775b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772cd697",
   "metadata": {},
   "outputs": [],
   "source": [
    "val2, pol2 = policy_iter(num_s, num_a, state, action, trans_model, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b7f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results into a text file\n",
    "\n",
    "file = open('sol-PI-mdp-2-2.txt','w')\n",
    "lines = []\n",
    "for s in state:\n",
    "    lines.append(f\"{'{:.6f}'.format(round(val2[s],6))} {pol2[s]}\\n\")\n",
    "file.writelines(lines)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff76d0f",
   "metadata": {},
   "source": [
    "#### Upon comparison with the provided solutions, the obtained results agree uptil the least significant digit (6th and 4th decimal place). This could further be improved by decreasing the margin of error (MAX_ERROR) allowed. For example, the values match upto the 6th decimal place when MAX_ERROR = 10^-8 and lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
